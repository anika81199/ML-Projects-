{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "historic-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries:\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "first-wheel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the path to our eye dataset: \n",
    "Directory = \"/Users/anikashrivastava/Downloads/driver-drowsiness-detection-Project/dataset_new/train\"\n",
    "# specify two categories on which we want to train our data:\n",
    "CATEGORIES = ['Closed' , 'Open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "level-spine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting image size:\n",
    "img_size = 24\n",
    "data = []\n",
    "\n",
    "#iterating over each image and get the image in array form,\n",
    "for category in CATEGORIES:\n",
    "    folder = os.path.join(Directory,category)\n",
    "    label = CATEGORIES.index(category)\n",
    "    for img in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, img)\n",
    "        img_arr = cv2.imread(img_path)\n",
    "        img_arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2GRAY)\n",
    "        img_arr = cv2.resize(img_arr,(img_size, img_size),1)\n",
    "        data.append([img_arr , label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ce107c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 24)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ready-drove",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1234"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the length of data:\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "japanese-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we shuffle the data to get random images of open eyes and closed eyes:\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cognitive-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing features and label for training the model: \n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for features,label in data:\n",
    "    X.append(features)\n",
    "    Y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "answering-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#covert them into array:\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "headed-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data into system:\n",
    "pickle.dump(X , open('X.pkl' , 'wb'))\n",
    "pickle.dump(Y , open('Y.pkl' , 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "pretty-constitution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the image array:\n",
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "scheduled-silver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.85098039, 0.82352941, 0.78431373, ..., 0.76470588,\n",
       "         0.7372549 , 0.61176471],\n",
       "        [0.83921569, 0.79215686, 0.76862745, ..., 0.8       ,\n",
       "         0.75294118, 0.68235294],\n",
       "        [0.82745098, 0.79607843, 0.75686275, ..., 0.79215686,\n",
       "         0.76470588, 0.72941176],\n",
       "        ...,\n",
       "        [0.85098039, 0.85882353, 0.83529412, ..., 0.81568627,\n",
       "         0.81568627, 0.81176471],\n",
       "        [0.85098039, 0.85098039, 0.83137255, ..., 0.81176471,\n",
       "         0.83137255, 0.82745098],\n",
       "        [0.85098039, 0.84313725, 0.84313725, ..., 0.82745098,\n",
       "         0.83137255, 0.83137255]],\n",
       "\n",
       "       [[0.82745098, 0.81176471, 0.81568627, ..., 0.64705882,\n",
       "         0.7254902 , 0.71764706],\n",
       "        [0.80392157, 0.79215686, 0.79215686, ..., 0.65882353,\n",
       "         0.70980392, 0.70196078],\n",
       "        [0.78823529, 0.76078431, 0.7372549 , ..., 0.63529412,\n",
       "         0.69411765, 0.71764706],\n",
       "        ...,\n",
       "        [0.76078431, 0.73333333, 0.70196078, ..., 0.64705882,\n",
       "         0.7254902 , 0.74509804],\n",
       "        [0.77254902, 0.76470588, 0.76470588, ..., 0.68235294,\n",
       "         0.7254902 , 0.7372549 ],\n",
       "        [0.7254902 , 0.78039216, 0.77254902, ..., 0.67058824,\n",
       "         0.71372549, 0.73333333]],\n",
       "\n",
       "       [[0.61960784, 0.63137255, 0.63921569, ..., 0.54509804,\n",
       "         0.54117647, 0.5254902 ],\n",
       "        [0.62352941, 0.63137255, 0.66666667, ..., 0.5372549 ,\n",
       "         0.54509804, 0.51372549],\n",
       "        [0.62352941, 0.65098039, 0.6745098 , ..., 0.51372549,\n",
       "         0.5254902 , 0.51372549],\n",
       "        ...,\n",
       "        [0.65882353, 0.64313725, 0.61568627, ..., 0.58431373,\n",
       "         0.62352941, 0.65098039],\n",
       "        [0.65490196, 0.65882353, 0.63137255, ..., 0.61176471,\n",
       "         0.63921569, 0.65882353],\n",
       "        [0.6627451 , 0.65882353, 0.64313725, ..., 0.62352941,\n",
       "         0.64705882, 0.65882353]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.42745098, 0.43137255, 0.42745098, ..., 0.2745098 ,\n",
       "         0.23921569, 0.20784314],\n",
       "        [0.41960784, 0.43137255, 0.42745098, ..., 0.2745098 ,\n",
       "         0.22745098, 0.18039216],\n",
       "        [0.40784314, 0.40784314, 0.40784314, ..., 0.2745098 ,\n",
       "         0.23137255, 0.16078431],\n",
       "        ...,\n",
       "        [0.45098039, 0.41960784, 0.37254902, ..., 0.4627451 ,\n",
       "         0.45098039, 0.43137255],\n",
       "        [0.45490196, 0.45098039, 0.44313725, ..., 0.46666667,\n",
       "         0.4627451 , 0.42352941],\n",
       "        [0.47058824, 0.47843137, 0.49019608, ..., 0.47843137,\n",
       "         0.47058824, 0.44705882]],\n",
       "\n",
       "       [[0.49019608, 0.48627451, 0.52941176, ..., 0.76862745,\n",
       "         0.81176471, 0.82745098],\n",
       "        [0.47843137, 0.4627451 , 0.5372549 , ..., 0.79607843,\n",
       "         0.77647059, 0.81568627],\n",
       "        [0.44705882, 0.4627451 , 0.54117647, ..., 0.65882353,\n",
       "         0.77647059, 0.78431373],\n",
       "        ...,\n",
       "        [0.60392157, 0.59607843, 0.65490196, ..., 0.68235294,\n",
       "         0.69803922, 0.64313725],\n",
       "        [0.57254902, 0.60392157, 0.63921569, ..., 0.66666667,\n",
       "         0.67843137, 0.62745098],\n",
       "        [0.59607843, 0.63529412, 0.65882353, ..., 0.68235294,\n",
       "         0.65490196, 0.60784314]],\n",
       "\n",
       "       [[0.43137255, 0.52941176, 0.56078431, ..., 0.85882353,\n",
       "         0.85098039, 0.84705882],\n",
       "        [0.45098039, 0.51764706, 0.54901961, ..., 0.87058824,\n",
       "         0.85490196, 0.85490196],\n",
       "        [0.4745098 , 0.49803922, 0.53333333, ..., 0.85098039,\n",
       "         0.84705882, 0.82745098],\n",
       "        ...,\n",
       "        [0.65098039, 0.65490196, 0.65098039, ..., 0.49019608,\n",
       "         0.53333333, 0.6       ],\n",
       "        [0.63529412, 0.64313725, 0.64705882, ..., 0.56078431,\n",
       "         0.57254902, 0.63137255],\n",
       "        [0.61568627, 0.62745098, 0.63529412, ..., 0.6       ,\n",
       "         0.62745098, 0.64313725]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "current-pasta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1234, 24, 24, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape the X array to (24,24,1)\n",
    "img_rows,img_cols = 24,24\n",
    "X = X.reshape(X.shape[0],img_rows,img_cols,1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "inner-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will be using keras to create the model:\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D , MaxPooling2D , Flatten , Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "soviet-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model:\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64 , (3,3) , activation = 'relu' , input_shape= X.shape[1:]))\n",
    "model.add(MaxPooling2D((1,1)))\n",
    "\n",
    "model.add(Conv2D(64 , (3,3) , activation = 'relu'))\n",
    "model.add(MaxPooling2D((1,1)))\n",
    "\n",
    "model.add(Conv2D(64 , (3,3) , activation = 'relu'))\n",
    "model.add(MaxPooling2D((1,1)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(2, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "seven-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model that we have created\n",
    "model.compile(optimizer = 'adam' , loss = 'sparse_categorical_crossentropy' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "nasty-measurement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 15:30:55.976599: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 1s 28ms/step - loss: 0.4065 - accuracy: 0.8108 - val_loss: 0.1903 - val_accuracy: 0.9194\n",
      "Epoch 2/5\n",
      "35/35 [==============================] - 1s 25ms/step - loss: 0.1467 - accuracy: 0.9441 - val_loss: 0.2149 - val_accuracy: 0.9113\n",
      "Epoch 3/5\n",
      "35/35 [==============================] - 1s 25ms/step - loss: 0.1081 - accuracy: 0.9631 - val_loss: 0.1342 - val_accuracy: 0.9435\n",
      "Epoch 4/5\n",
      "35/35 [==============================] - 1s 25ms/step - loss: 0.0823 - accuracy: 0.9694 - val_loss: 0.1551 - val_accuracy: 0.9435\n",
      "Epoch 5/5\n",
      "35/35 [==============================] - 1s 25ms/step - loss: 0.0728 - accuracy: 0.9766 - val_loss: 0.0899 - val_accuracy: 0.9677\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1753dbc10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit X , Y to the model to see accuracy of model:\n",
    "model.fit(X, Y, epochs = 5 , validation_split = 0.1 , batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-exclusive",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "purple-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and architecture to single file\n",
    "model.save(\"custmodel1.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
